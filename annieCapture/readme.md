[![MIT licensed](https://img.shields.io/badge/license-MIT-blue.svg)](https://opensource.org/licenses/MIT)

# AMD Neural Net Inference Engine Capture

ANNIE Capture is a python application that uses the pre-trained Caffe models that are converted into OpenVX Graph, using ANNIE model compiler, to run the neural net on a live camera. The ANNIE model compiler converts the pre-trained model into libannmodule.so and libannpython.so, using these libraries and the weights.bin file generated by the model compiler, the ANNIE Capture runs the neural net model on the live camera. The capture application currently supports classification models.


The ANNIE Capture can be used inside the docker application or by installing the Neural Net Model Profiler.

## Inference Prerequisites
* [ROCm](https://rocm.github.io/install.html) - 1.7.148
* [rocm-cmake](https://github.com/RadeonOpenCompute/rocm-cmake) - github master:3f43e2d 
* [MIOpenGEMM](https://github.com/ROCmSoftwarePlatform/MIOpenGEMM) - 1.1.5
* [MIOpen](https://github.com/ROCmSoftwarePlatform/MIOpen/releases/tag/1.3.0) - 1.3.0
* [Protobuf](https://github.com/google/protobuf) - github master:ef9d868
* [OpenCV](https://github.com/opencv/opencv/releases/tag/3.3.0) - 3.3.0
* [AMDOVX-Core](https://github.com/GPUOpen-ProfessionalCompute-Libraries/amdovx-core) - github develop:2a446b9
* [AMDOVX-Modules](https://github.com/GPUOpen-ProfessionalCompute-Libraries/amdovx-modules) - github develop:c7586b8

## Inference Workflow

![Figure 1](https://gpuopen-professionalcompute-libraries.github.io/AMD-Neural-Net-Inference-Engine/images/block_diagram_inference_workflow.png "High Level Inference Workflow")

## Inference Docker WorkFlow

### Prerequisites
* ubuntu 16.04.3 LTS
* [rocm supported hardware](https://rocm.github.io/hardware.html) (Suggested: Vega 10 Frontier)

### Docker Workflow

* Step 1 - **Install rocm-dkms**
````
sudo apt update
sudo apt dist-upgrade
sudo apt install libnuma-dev
sudo reboot
````
````
sudo apt install linux-headers-4.13.0-32-generic linux-image-4.13.0-32-generic linux-image-extra-4.13.0-32-generic linux-signed-image-4.13.0-32-generic
sudo reboot 
````
````
wget -qO - http://repo.radeon.com/rocm/apt/debian/rocm.gpg.key | sudo apt-key add -
sudo sh -c 'echo deb [arch=amd64] http://repo.radeon.com/rocm/apt/debian/ xenial main > /etc/apt/sources.list.d/rocm.list'
sudo apt update
sudo apt install rocm-dkms
sudo reboot
````

* Step 2 - **Setup Docker**
````
sudo apt-get install curl
sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
sudo apt-get update
apt-cache policy docker-ce
sudo apt-get install -y docker-ce
sudo systemctl status docker
````

* Step 3 - **Get Docker Image**
````
sudo docker pull kiritigowda/amd-neural-net-inference
````

* Step 4 - **Run the docker image**
````
sudo docker run -it --device=/dev/kfd --device=/dev/dri --cap-add=SYS_RAWIO --device=/dev/mem --group-add video --network host kiritigowda/amd-neural-net-inference
````
  * Optional: Map local host directory on the docker image
    * option to map the local host directory with trained caffe models to be accessed on the docker image.
    * usage: -v {LOCAL_HOST_DIRECTORY_PATH}:{DOCKER_DIRECTORY_PATH} 
````
sudo docker run -it -v /home/:/root/hostDrive/ --device=/dev/kfd --device=/dev/dri --cap-add=SYS_RAWIO --device=/dev/mem --group-add video --network host kiritigowda/amd-neural-net-inference
````

* Step 5 - **Use Model Compiler**

#### caffe2nnir & nnir2openvx - Trained Caffe Model conversion to Neural Net Intermediate Representation (NNIR) to OpenVX Graph

![Figure 2](https://gpuopen-professionalcompute-libraries.github.io/AMD-Neural-Net-Inference-Engine/images/NetFlow.png "Inference Workflow")

1. Convert net.caffemodel into NNIR model using the following command
   ````
	    python caffe2nnir.py <net.caffeModel> <nnirOutputFolder> --input-dims n,c,h,w [--verbose 0|1]
   ````
2. Compile NNIR model into OpenVX C code with CMakelists.txt for compiling and building inference library
   ````
	    python nnir2openvx.py <nnirModelFolder> <nnirModelOutputFolder>
   ````
3. cmake and make the project inside the nnirModelOutputFolder, follow the sample below
4. Run anntest application for testing inference with input and output tensor
5. The shared C library (libannmodule.so) can be used in customer application as well
6. To run a caffemodel on the host machine inside docker use the [sample](#sample-1)

##### Sample	
````
. ~/rocmrc 
cd ~/AMDOVX/
mkdir build
cd build/
python ../amdovx-modules/utils/model_compiler/python/caffe2nnir.py ../caffeModels/resnet50/resnet50.caffemodel resnet50 --input-dims 1,3,224,224
python ../amdovx-modules/utils/model_compiler/python/nnir2openvx.py resnet50/ resnet50-build
cd resnet50-build/
cmake .
make
./anntest weights.bin 
````
##### Sample Output
````
root@RyzenUbuntu:~/AMDOVX/build/resnet50-build# ./anntest weights.bin 
OK: loaded 22 kernels from libvx_nn.so
OK: OpenVX using GPU device#0 (gfx900) [OpenCL 1.2 ] [SvmCaps 0 1]
OK: graph initialization with annAddToGraph() took 2927.948 msec
OK: vxProcessGraph() took 43.503 msec (1st iteration)
OK: vxProcessGraph() took 6.046 msec (average over 100 iterations)
OK: OpenCL buffer usage: 114286400, 274/274
OK: successful
````

* Step 6 - **Get the ANNIE Capture Module**

````
git clone https://github.com/kiritigowda/help
````
The help module contains annieCapture.

* Step 7 - **Copy .so's into annieCapture**
 
 Copy the libannmodule.so,libannpython.so, & weights.bin built inside the resnet50-build folder into the annieCapture folder.

 * Step 8 - **Run ANNIE Capture**

 To run the capture make sure that you have a webcam connected and run the following command inside the annieCapture folder.

 ````
 python annieCapture.py --capture 0
 ````
